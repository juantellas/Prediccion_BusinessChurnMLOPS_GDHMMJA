{"version":"1","records":[{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Descripción"},"type":"lvl2","url":"/#descripci-n","position":2},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Descripción"},"content":"Proyecto de Machine Learning para predecir el abandono de clientes (churn) en una compañía de telecomunicaciones.Se implementan modelos de Random Forest y XGBoost con ajuste de hiperparámetros, además de técnicas de interpretabilidad para explicar las predicciones (LIME).","type":"content","url":"/#descripci-n","position":3},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Estructura del Proyecto"},"type":"lvl2","url":"/#estructura-del-proyecto","position":4},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Estructura del Proyecto"},"content":"telco-churn-mlops/\n├── data/\n│ └── telco_churn.csv # Dataset original\n├── notebooks/\n│ ├── 1_eda_preprocessing.ipynb # Análisis exploratorio y preprocesamiento\n│ ├── 2_model_training.ipynb # Entrenamiento y evaluación de modelos\n│ └── 3_interpretability.ipynb # Interpretación de predicciones con LIME\n├── app/\n│ ├── api.py # API REST con FastAPI\n│ ├── schemas.py # Modelos Pydantic\n│ └── model.joblib # Modelo XGBoost entrenado\n├── tests/\n│ ├── test_api.py # Pruebas unitarias del endpoint\n│ └── test_model.py # Validación de modelo\n├── Dockerfile # Contenedor Docker\n├── requirements.txt # Dependencias Python\n├── .github/workflows/ci.yml # CI/CD GitHub Actions\n└── README.md # Documentación","type":"content","url":"/#estructura-del-proyecto","position":5},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Instalación y Uso Local"},"type":"lvl2","url":"/#instalaci-n-y-uso-local","position":6},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Instalación y Uso Local"},"content":"Crear un entorno virtual y activarlo (opcional pero recomendado):\n\npython -m venv venv\nsource venv/bin/activate  # Linux/macOS\nvenv\\Scripts\\activate     # Windows\n\nInstalar dependencias:\n\npip install --upgrade pip\npip install -r requirements.txt\n\nEjecutar la API en modo desarrollo:\n\nuvicorn app.api:app --reload --host 0.0.0.0 --port 8000\n\nProbar endpoint /predict (ejemplo con curl):\n\ncurl -X POST “\n\nhttp://​127​.0​.0​.1:8000​/predict” -H “Content-Type: application/json” -d ‘{\n“gender”: “Female”,\n“senior”: “No”,\n“partner”: “Yes”,\n“dependents”: “No”,\n“phone”: “Yes”,\n“phone_multiple”: “No”,\n“internet”: “Yes”,\n“internet_security”: “No”,\n“internet_backup”: “No”,\n“internet_protection”: “No”,\n“internet_support”: “No”,\n“streaming_tv”: “No”,\n“streaming_movies”: “No”,\n“contract”: “Month-to-month”,\n“paperless”: “Yes”,\n“payment”: “Electronic check”,\n“tenure”: 5,\n“charges_monthly”: 70.35\n}’\n\nRespuesta esperada:\n\n{\n“churn_probability”: 0.703,\n“churn_prediction”: “Churn”","type":"content","url":"/#instalaci-n-y-uso-local","position":7},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Docker"},"type":"lvl2","url":"/#docker","position":8},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Docker"},"content":"Construir la imagen:\n\ndocker build -t telco-churn-api .\n\nEjecutar el contenedor:\n\ndocker run -p 8000:8000 telco-churn-api\n\nLa API estará disponible en \n\nhttp://​localhost:8000.\n\nEndpoints\nEndpoint\tMétodo\tDescripción\n/predict\tPOST\tRecibe JSON con features del cliente y retorna probabilidad de churn y predicción final (Churn o No Churn).\nTests","type":"content","url":"/#docker","position":9},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Ejecutar tests de la API:"},"type":"lvl2","url":"/#ejecutar-tests-de-la-api","position":10},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Ejecutar tests de la API:"},"content":"pytest -v tests/test_api.py","type":"content","url":"/#ejecutar-tests-de-la-api","position":11},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Validación del modelo:"},"type":"lvl2","url":"/#validaci-n-del-modelo","position":12},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Validación del modelo:"},"content":"pytest -v tests/test_model.py","type":"content","url":"/#validaci-n-del-modelo","position":13},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Interpretabilidad"},"type":"lvl2","url":"/#interpretabilidad","position":14},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Interpretabilidad"},"content":"Se incluye un notebook para interpretar predicciones usando LIME, lo que permite explicar qué features contribuyen más a la predicción de churn.","type":"content","url":"/#interpretabilidad","position":15},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Licencia"},"type":"lvl2","url":"/#licencia","position":16},{"hierarchy":{"lvl1":"Predicción de Churn en Telecomunicaciones","lvl2":"Licencia"},"content":"MIT License – libre uso y modificación.","type":"content","url":"/#licencia","position":17},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos"},"type":"lvl1","url":"/eda","position":0},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos"},"content":"","type":"content","url":"/eda","position":1},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl2":"1.1 Carga de librerías, datos y verificación de su estado."},"type":"lvl2","url":"/eda#id-1-1-carga-de-librer-as-datos-y-verificaci-n-de-su-estado","position":2},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl2":"1.1 Carga de librerías, datos y verificación de su estado."},"content":"\n\nEn esta sección realizaremos el cargue de los datos a analizar y de las librerías que nos ayudarán a hacer esto posible.\n\nfrom sklearnex import patch_sklearn\npatch_sklearn()\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\nimport time\nimport statsmodels\nimport os\n\nfrom scipy.sparse import hstack, csr_matrix\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import shapiro\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tools.tools import add_constant\n\n\nAntes de empezar, procederemos a hacer algunos ajustes que nos ayudarán a la hora de visualizar más adelante. Junto a ello, cargaremos los datos y funciones que ayudarán a desarrollar esta exploración.\n\nsns.set(style=\"whitegrid\")\nplt.rcParams[\"figure.figsize\"] = (10, 6)\n\ndf = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n\ndef analizar_dataframe(df, nombre=\"DataFrame\"):\n    from IPython.display import display\n    \n    print(f\"\\n Análisis exploratorio de: {nombre}\")\n    print(\"=\" * 75)\n    \n    print(f\"Filas: {df.shape[0]:,}  |  Columnas: {df.shape[1]}\")\n    print(\"=\" * 75)\n    \n    print(df.dtypes)\n    print(\"=\" * 75)\n    \n    display(df.head())\n    \n\nanalizar_dataframe(df, nombre=\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n\nEste dataset relacionado con churn tiene un total de 7,043 filas o registros, teniendo cada unas 20 columnas o variables, dando aproximadamente 140.000 observaciones, con la mayoría de variables teniendo la característica de objeto o caracteres, y solo teniendo pocas de valor numérico.\n\nPodemos destacar que la variable MonthlyCharges, a pesar de tener valores numéricos, está considerada como object. Junto a esto, la variable SeniorCitizen está escrita como valores binarios. Por el desarrollo del análisis, vamos a cambiar los valores y el tipo de variable a continuación.\n\ndef convertir_binaria_a_si_no(df, columnas):\n    df_copy = df.copy()\n    for col in columnas:\n        if col in df_copy.columns:\n            df_copy[col] = df_copy[col].map({0: \"No\", 1: \"Yes\"}).astype(\"object\")\n    return df_copy\n\ndf = convertir_binaria_a_si_no(df, [\"SeniorCitizen\"])\n\ndef convertir_columna_a_float(df, columna):\n    df_copy = df.copy()\n    if columna in df_copy.columns:\n        if not pd.api.types.is_numeric_dtype(df_copy[columna]):\n            df_copy[columna] = (\n                df_copy[columna]\n                .astype(str)\n                .str.replace(r\"[^0-9\\.-]\", \"\", regex=True)  \n                .replace(\"\", \"0\")  \n                .astype(float)\n            )\n    return df_copy\n\n\ndf = convertir_columna_a_float(df, \"MonthlyCharges\")\ndf = convertir_columna_a_float(df, \"TotalCharges\")\n\ndf.dtypes.value_counts()\n\nCon estos cambios, podemos corroborar la información si volvemos a ver el resumen de los datos.\n\ndf.info()\n\npd.set_option('display.max_columns', None)\ndf.head()\n\n","type":"content","url":"/eda#id-1-1-carga-de-librer-as-datos-y-verificaci-n-de-su-estado","position":3},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl2":"1.2 Verificación de datos faltantes y outliers."},"type":"lvl2","url":"/eda#id-1-2-verificaci-n-de-datos-faltantes-y-outliers","position":4},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl2":"1.2 Verificación de datos faltantes y outliers."},"content":"\n\nA continuación, usaremos un mapa de calor para observar si existen datos faltantes dentro de nuestro dataset.\n\ndef mostrar_faltantes(df):\n    faltantes = df.isnull().sum()\n    porcentaje = (faltantes / len(df)) * 100\n\n    tabla_faltantes = pd.DataFrame({\n        'Valores faltantes': faltantes,\n        'Porcentaje (%)': porcentaje\n    })\n\n    tabla_faltantes = tabla_faltantes[tabla_faltantes['Valores faltantes'] > 0]\n    tabla_faltantes.sort_values('Porcentaje (%)', ascending=False)\n    return tabla_faltantes\n\nplt.figure(figsize=(12, 6))\nsns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='Blues')\nplt.title(\"Mapa de calor de valores faltantes\", fontsize=14)\nplt.show()\n\nAfortunadamente, en este caso, no vemos presencia de datos faltantes; esto lo podemos corroborar viendo los porcentajes de faltantes para cada variable en forma tabular.\n\nmostrar_faltantes(df)\n\nJunto a lo anterior, verifiquemos si existen problemas con registros duplicados.\n\nduplicados_totales = df.duplicated().sum()\nprint(\"Duplicados totales en el dataset:\", duplicados_totales)\n\ndf[df.duplicated(keep=False)].head()\n\nAl parecer, tampoco hay registros duplicados en este dataset. Finalmente, veamos los datos atípicos que tenemos para nuestras variables numéricas.\n\nnum_cols = df.select_dtypes(include=[np.number]).columns\n\nprint(num_cols)\n\noutlier_summary = {}\n\nfor col in num_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower = Q1 - 1.5 * IQR\n    upper = Q3 + 1.5 * IQR\n    outliers = df[(df[col] < lower) | (df[col] > upper)][col]\n    outlier_summary[col] = len(outliers)\n\noutlier_df = pd.DataFrame.from_dict(outlier_summary, orient='index', columns=['n_outliers'])\noutlier_df['porcentaje'] = 100 * outlier_df['n_outliers'] / len(df)\noutlier_df.sort_values('porcentaje', ascending=False)\n\nComo se puede observar, no existen prevalencias de datos faltantes, duplicados o atípicos. Esto lo hará más eficaz a la hora de observar el análisis debido a su estado.\n\n","type":"content","url":"/eda#id-1-2-verificaci-n-de-datos-faltantes-y-outliers","position":5},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl2":"1.3 Verificación de correlación y multicolinealidad."},"type":"lvl2","url":"/eda#id-1-3-verificaci-n-de-correlaci-n-y-multicolinealidad","position":6},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl2":"1.3 Verificación de correlación y multicolinealidad."},"content":"\n\nA continuación, observemos si en los datos hay índices de multicolinealidad. Para esto, haremos un mapa de calor, y posteriormente se hará el cálculo del VIF para tener constancia de estos resultados.\n\nnum_vars = df.select_dtypes(include=[\"int64\", \"float64\"])\ncorr_matrix = num_vars.corr()\n\nplt.figure(figsize=(12,8))\nsns.heatmap(\n    corr_matrix,\n    cmap=\"Blues\",\n    center=0,\n    annot=True,        \n    fmt=\".2f\",         \n    linewidths=0.5,    \n    square=True\n)\nplt.title(\"Matriz de Correlación\", fontsize=14)\nplt.show()\n\nAquí, la variable TotalCharges o costo total tiene un índice de correlación de 0.83, lo que indica que hay una correlación entre esta variable y otras. Observemos su comportamiento calculando el VIF.\n\ndf_num = num_vars.dropna()\n\nX = add_constant(df_num)\n\nvif_data = pd.DataFrame()\nvif_data[\"Variable\"] = X.columns\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n                   for i in range(X.shape[1])]\n\n\npd.set_option(\"display.max_rows\", None)  \nprint(vif_data) \n\nNos damos cuenta de que el VIF para TotalCharges es de casi 10, por lo que sospechamos un alto índice de multicolinealidad en esta variable. Esto tendría sentido, ya que podríamos establecer que el costo total (TotalCharges) es el producto entre el total de meses y el costo mensual. Para esto, hagamos una nueva columna que tenga este producto en cuenta.\n\ndf[\"es_multiplo\"] = np.isclose(df[\"TotalCharges\"], df[\"tenure\"] * df[\"MonthlyCharges\"], atol=1)\nprint(df[\"es_multiplo\"].value_counts(dropna=False))\n\n\nGracias a lo anterior, vemos que casi el 10% de los datos se pueden expresar como combinación lineal, claro, este valor puede variar, pero se observa una dependencia lineal entre las columnas MonthlyCharges y tenure, con esto en mente, vamos a descartarla de nuestro dataset y recalculamos el VIF para observar los cambios que hemos tenido.\n\ndf.drop([\"TotalCharges\",\"es_multiplo\"], axis=1, inplace=True, errors=\"ignore\")\n\nnum_vars = df.select_dtypes(include=[\"int64\", \"float64\"])\ndf_num = num_vars.dropna()\n\nX = add_constant(df_num)\n\nvif_data = pd.DataFrame()\nvif_data[\"Variable\"] = X.columns\nvif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n                   for i in range(X.shape[1])]\n\n\npd.set_option(\"display.max_rows\", None)  \nprint(vif_data) \n\nCon este cálculo hecho, vemos cómo el VIF ha disminuido drásticamente (casi por debajo de 1), con valores muy bajos en comparación de antes. Ahora, usemos la V de Cramer para ver si hay multicolinealidad entre variables categorías.\n\ndef cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x, y)\n    chi2 = chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2 / n\n    r, k = confusion_matrix.shape\n    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n    rcorr = r - ((r-1)**2)/(n-1)\n    kcorr = k - ((k-1)**2)/(n-1)\n    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n\ncat_vars = df.select_dtypes(include=[\"object\"]).columns\n\nassoc_matrix = pd.DataFrame(\n    np.zeros((len(cat_vars), len(cat_vars))),\n    index=cat_vars,\n    columns=cat_vars\n)\n\nfor col1 in cat_vars:\n    for col2 in cat_vars:\n        if col1 != col2:\n            assoc_matrix.loc[col1, col2] = cramers_v(df[col1], df[col2])\n\nprint(assoc_matrix.round(3))\n\nplt.figure(figsize=(12,8))\nsns.heatmap(assoc_matrix, cmap=\"viridis\", annot=False)\nplt.title(\"Matriz de Asociación Categórica (Cramér's V)\")\nplt.show()\n\nDe esta matriz de asociación de variables categoricas, vemos que, en su gran mayoría, su relación no presenta problemas de multicolinealidad, con valores oscilando entre el 0.1 y el -0.025. Con esto en mente, también podremos eliminar la variable customerID al ser este un indicador único, que no aporta información tanto al análisis o al modelo posterior.\n\ndf.drop([\"customerID\"], axis=1, inplace=True, errors=\"ignore\")\ndf.head()\n\n","type":"content","url":"/eda#id-1-3-verificaci-n-de-correlaci-n-y-multicolinealidad","position":7},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl2":"1.4 Análisis Exploratorio."},"type":"lvl2","url":"/eda#id-1-4-an-lisis-exploratorio","position":8},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl2":"1.4 Análisis Exploratorio."},"content":"\n\n","type":"content","url":"/eda#id-1-4-an-lisis-exploratorio","position":9},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl3":"1.4.0 Previo al análisis","lvl2":"1.4 Análisis Exploratorio."},"type":"lvl3","url":"/eda#id-1-4-0-previo-al-an-lisis","position":10},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl3":"1.4.0 Previo al análisis","lvl2":"1.4 Análisis Exploratorio."},"content":"\n\nAhora, por temas de sencillez a la hora de analizar, renombraremos las variables a formas más sencillas:\n\ndf.rename(columns={\n    \"SeniorCitizen\": \"senior\",\n    \"Partner\": \"partner\",\n    \"Dependents\": \"dependents\",        \n    \"PhoneService\": \"phone\",\n    \"MultipleLines\": \"phone_multiple\",\n    \"InternetService\": \"internet\",\n    \"OnlineSecurity\": \"internet_security\",\n    \"OnlineBackup\": \"internet_backup\",\n    \"DeviceProtection\": \"internet_protection\",\n    \"TechSupport\": \"internet_support\",\n    \"StreamingTV\": \"streaming_tv\",\n    \"StreamingMovies\": \"streaming_movies\",\n    \"Contract\": \"contract\",\n    \"PaperlessBilling\": \"paperless\",\n    \"PaymentMethod\": \"payment\",\n    \"MonthlyCharges\": \"charges_monthly\",\n    \"Churn\": \"churn\",\n}, inplace=True)\n\n\nEn este caso, nuestra variable de interés es churn, la cual indica si un usuario abandonó o no. Veamos la proporción antes de ver el análisis.\n\ndf[\"churn\"] = df[\"churn\"].map({\"Yes\": 1, \"No\": 0})\nprint(df[\"churn\"].value_counts(dropna=False))\n\n\nLa variable churn presenta un desbalance, con 5174 registros de 0 y 1869 registros de 1. En este contexto, el 0 significa que el usuario no abandonó, mientras que 1 implica que el usuario abandonó.\n\ndf.to_csv(\"data_churn_EDA.csv\", index=False)\n\n","type":"content","url":"/eda#id-1-4-0-previo-al-an-lisis","position":11},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl3":"1.4.1 Análisis para variables categoricas.","lvl2":"1.4 Análisis Exploratorio."},"type":"lvl3","url":"/eda#id-1-4-1-an-lisis-para-variables-categoricas","position":12},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl3":"1.4.1 Análisis para variables categoricas.","lvl2":"1.4 Análisis Exploratorio."},"content":"\n\nEn primera vista, veamos cómo la variable objetivo se comporta junto a otras variables categoricas.\n\nplt.figure(figsize=(6,4))\nsns.countplot(data=df, x='churn', palette='Blues_r')\nplt.title(\"No Abandono (no Churn) vs Abandono (Churn)\")\nplt.ylabel(\"Conteo\") \nplt.xlabel(\"Estado del usuario (0 = No churn, 1 = Churn)\")\nplt.show()\n\nEste gráfico de barras representa la misma proporción vista en la sección anterior, donde existe un desbalance entre ambos usuarios.\n\nplt.figure(figsize=(12,4))\nsns.countplot(data=df, x=\"gender\", hue=\"churn\", palette=\"Blues_r\")\nplt.title(\"Distribución de gender según churn\")\nplt.xlabel(\"gender\")\nplt.ylabel(\"Cantidad\")\nplt.show()\n\nSi observamos la distribución de género y los usuarios que hicieron churn y no churn, vemos que la distribución es muy similar de ambos lados, es decir, de los usuarios que abandonaron y no abandonaron. Podemos destacar que ligeramente hay más usuarios hombres que mujeres dentro del dataset.\n\nplt.figure(figsize=(12,4))\nsns.countplot(data=df, x=\"phone_multiple\", hue=\"churn\", palette=\"Blues_r\")\nplt.title(\"Distribución de phone_multiple según churn\")\nplt.xlabel(\"phone\")\nplt.ylabel(\"Cantidad\")\nplt.show()\n\nAquí tenemos la variable phone_multiple, lo que indica si un usuario tiene más de una línea telefónica activa. Dentro de estos resultados, vemos que la mayoría de los usuarios en las diferentes categorías no han abandonado, con la gran proporción de estos en la sección de “No”, es decir, que solo tienen una línea telefónica. Curiosamente, parece que es más común tener más de una línea activa a no tener líneas de teléfono activas.\n\nplt.figure(figsize=(12,4))\nsns.countplot(data=df, x=\"internet\", hue=\"churn\", palette=\"Blues_r\")\nplt.title(\"Distribución de internet según churn\")\nplt.xlabel(\"internet\")\nplt.ylabel(\"Cantidad\")\nplt.show()\n\nPara la variable *Internet, observamos un comportamiento diferente a lo anterior visto. Empecemos con que existe una gran proporción de usuarios que no tienen redes de internet, pero aquellos que sí se dividen en dos grandes categorías: DSL y “Fiber optic”. De estos, los usuarios que tienen “Fiber optic” tienen mayor prevalencia a abandonar que aquellos de DSL. Este resultado podría darnos indicios sobre aquellas variables que más afecten a la hora de modelar.\n\nplt.figure(figsize=(12,4))\nsns.countplot(data=df, x=\"contract\", hue=\"churn\", palette=\"Blues_r\")\nplt.title(\"Distribución de contract según churn\")\nplt.xlabel(\"contract\")\nplt.ylabel(\"Cantidad\")\nplt.show()\n\nSi observamos ahora la variable contract, que indica el tipo de contrato que tienen los usuarios, vemos tres categorías: Month-to-month, One year y Two Year. Los usuarios que tengan contratos de un año o más tienen muy baja tendencia a hacer churn, mientras que aquellos usuarios que tengan de mes a mes si son más propensos a abandonar.\n\nplt.figure(figsize=(12,4))\nsns.countplot(data=df, x=\"payment\", hue=\"churn\", palette=\"Blues_r\")\nplt.title(\"Distribución de payment según churn\")\nplt.xlabel(\"payment\")\nplt.ylabel(\"Cantidad\")\nplt.show()\n\nFinalmente, para los métodos de pago observamos una tendencia en relación con aquellos usuarios que son más propensos a abandonar: aquellos usuarios que reciban un cheque electrónico, a casi la misma proporción de aquellos que no abandonan, también suelen abandonar. Sin embargo, para el resto de métodos de pago, los usuarios mantienen una tasa baja de abandono.\n\n","type":"content","url":"/eda#id-1-4-1-an-lisis-para-variables-categoricas","position":13},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl3":"1.4.2 Análisis para variables numericas.","lvl2":"1.4 Análisis Exploratorio."},"type":"lvl3","url":"/eda#id-1-4-2-an-lisis-para-variables-numericas","position":14},{"hierarchy":{"lvl1":"1. Análisis Exploratorio de los Datos","lvl3":"1.4.2 Análisis para variables numericas.","lvl2":"1.4 Análisis Exploratorio."},"content":"\n\nAhora, haremos de forma análoga, pero con las variables numéricas.\n\nfig, axes = plt.subplots(1, 2, figsize=(16,5))\n\nsns.boxplot(data=df, x=\"churn\", y=\"tenure\", palette=\"Blues_r\", ax=axes[0])\naxes[0].set_title(\"tenure vs churn\")\naxes[0].set_ylabel(\"tenure (Meses)\")\n\nsns.histplot(data=df, x=\"tenure\", hue=\"churn\", palette=\"Blues_d\", bins=13, kde=True, alpha=0.6, ax=axes[1])\naxes[1].set_title(\"tenure (Tiempo de contrato en meses) segun churn\")\naxes[1].set_xlabel(\"tenure (Meses)\")\naxes[1].set_ylabel(\"Frecuencia\")\n\nplt.tight_layout()\nplt.show()\n\nPara la variable tenure, se observa que el comportamiento de los usuarios que abandonan parece seguir una tendencia. Aquellos usuarios que abandonan suelen tener poco tiempo con la empresa, de 0 a 10 meses, mientras que aquellos que no abandonan tienen un rango bastante amplio, de 10 a un máximo de 70 meses, siendo este intervalo superior a la moda para estos usuarios.\n\nfig, axes = plt.subplots(1, 2, figsize=(16,5))\n\nsns.boxplot(data=df, x=\"churn\", y=\"charges_monthly\", palette=\"Blues_r\", ax=axes[0])\naxes[0].set_title(\"charges_monthly vs churn\")\naxes[0].set_ylabel(\"charges_monthly (en USD)\")\n\nsns.histplot(data=df, x=\"charges_monthly\", hue=\"churn\", palette=\"Blues_d\", bins=13, kde=True, alpha=0.6, ax=axes[1])\naxes[1].set_title(\"charges_monthly segun churn\")\naxes[1].set_xlabel(\"charges_monthly (en USD)\")\naxes[1].set_ylabel(\"Frecuencia\")\n\nplt.tight_layout()\nplt.show()\n\nPara esta variable, charges_monthly, el costo mensual para ambos usuarios es casi constante. No existe un patrón o tendencia a seguir, con ambos usuarios teniendo costos similares, siendo los usuarios que no abandonan que tienen mayor variabilidad en costos. Cabe resaltar que ambos grupos poseen el mismo rango mínimo y máximo para los costos.\n\nCon esto en mente, podemos tener esto en cuenta y lo mismo que los resúmenes anteriores para usarlo como estrategias para el modelado, que se hará a continuación.","type":"content","url":"/eda#id-1-4-2-an-lisis-para-variables-numericas","position":15},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados"},"type":"lvl1","url":"/modelos","position":0},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados"},"content":"En esta seccion, vamos a empezar haciendo el preprocesado de los datos finales, y posteriormente modelando los diferentes modelos, con diferentes modificaciones en cada etapa.\n\n","type":"content","url":"/modelos","position":1},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"type":"lvl2","url":"/modelos#id-2-1-modelos-benchmark-randomforest-xgboost-catboost-lightgbm","position":2},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"content":"\n\nAntes de todo, vamos a empezar importando las librerias que usaremos.\n\nimport pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import (\n    classification_report, ConfusionMatrixDisplay, RocCurveDisplay,\n    accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom catboost.utils import get_gpu_device_count\n\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.metrics import (\n    confusion_matrix, ConfusionMatrixDisplay,\n    roc_curve, auc, classification_report\n)\n\nfrom imblearn.over_sampling import SMOTE\nimport joblib\nimport pikl\n\nActo seguido, vamos a cargar los datos y hacer la separacion de las columnas categoricas y numericas para entrenar el modelo y nuestras “X”. Este proceso va a ser analogo en todas las etapas.\n\ndf = pd.read_csv(\"data_churn_EDA.csv\")\n\nX = df.drop(\"churn\", axis=1)\ny = df[\"churn\"]\n\nnum_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\ncat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\nLuego de este split, vamos a aplicar el StandardScaler() a las variables numericas y OneHotEncoder a nuestras variables categoricas para futuro modelaje.\n\npreprocessor = ColumnTransformer([\n    (\"num\", StandardScaler(), num_cols),\n    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n])\n\nprint(\"Categóricas:\", cat_cols)\nprint(\"Numéricas:\", num_cols)\n\nAqui, usaremos solamente los modelos estandares:\n\nRandom Forest\n\nXGBoost\n\nCatBoost\n\nLightGBM\n\nmodels = {\n    \"RandomForest\": RandomForestClassifier(random_state=42),\n    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n    \"CatBoost\": CatBoostClassifier(verbose=0, random_seed=42),\n    \"LightGBM\": LGBMClassifier(random_state=42)\n}\n\nY con ello, tambien haremos los respectivos pipelines para evitar cualquier fuga de datos dentro del proceso.\n\npipe_rf = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", RandomForestClassifier(random_state=42))\n])\n\npipe_xgb = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42))\n])\n\npipe_cat = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", CatBoostClassifier(verbose=0, random_seed=42))\n])\n\npipe_lgb = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", LGBMClassifier(random_state=42))\n])\n\npipelines = {\n    \"RandomForest\": pipe_rf,\n    \"XGBoost\": pipe_xgb,\n    \"CatBoost\": pipe_cat,\n    \"LightGBM\": pipe_lgb\n}\n\nprint(\" Pipelines creados manualmente para cada modelo:\")\nfor name in pipelines:\n    print(f\" - {name}\")\n\nJunto a ello, a pesar de que no usaremos hiperparametros, usaremos validacion cruzada para entrenar los modelos, y acumularemos los resultados para analizarlos a nivel global mas adelante.\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nparam_grids_empty = {\n    \"RandomForest\": {},\n    \"XGBoost\": {},\n    \"CatBoost\": {},\n    \"LightGBM\": {}\n}\n\nresultados1 = []\n\n","type":"content","url":"/modelos#id-2-1-modelos-benchmark-randomforest-xgboost-catboost-lightgbm","position":3},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.1 RandomForest","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"type":"lvl3","url":"/modelos#id-2-1-1-randomforest","position":4},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.1 RandomForest","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"content":"\n\ngrid_rf = GridSearchCV(\n    estimator=pipe_rf,\n    param_grid={},  \n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_rf.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_rf = grid_rf.predict(X_test)\n\nprint(\"\\nResultados - RandomForest\")\nprint(classification_report(y_test, y_pred_rf))\nprint(\"Mejores parámetros:\", grid_rf.best_params_)\n\nresultados1.append({\n    \"Modelo\": \"RandomForest\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n    \"Recall\": recall_score(y_test, y_pred_rf),\n    \"Precision\": precision_score(y_test, y_pred_rf),\n    \"F1\": f1_score(y_test, y_pred_rf),\n    \"AUC\": roc_auc_score(y_test, y_pred_rf),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_rf.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nConfusionMatrixDisplay.from_estimator(\n    grid_rf, X_test, y_test, cmap=\"Blues\", ax=axes[0]\n)\naxes[0].set_title(\"Matriz de Confusión - RandomForest\")\n\nRocCurveDisplay.from_estimator(grid_rf, X_test, y_test, ax=axes[1])\naxes[1].plot([0, 1], [0, 1], \"k--\", label=\"Línea base (y=x)\")\naxes[1].set_title(\"Curva ROC - RandomForest\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo inicial de Random Forest nos da un resultado útil, presentando un rendimiento de prueba sólido con una Accuracy de 0.78 y un AUC de 0.81. La matriz de confusión demuestra un desempeño normal, enfatizando el desbalance que hay entre las clases, ya que la clase mayoritaria (positiva) tiene mayores tasas de clasificacion a diferencia de la clase negativa. En esta ultima clase, la tasa tanto de positivos como negativos es casi equivalente.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.69. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\n","type":"content","url":"/modelos#id-2-1-1-randomforest","position":5},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.2 XGBoost","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"type":"lvl3","url":"/modelos#id-2-1-2-xgboost","position":6},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.2 XGBoost","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"content":"\n\ngrid_xgb = GridSearchCV(\n    estimator=pipe_xgb,\n    param_grid={},\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_xgb.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_xgb = grid_xgb.predict(X_test)\n\nprint(\"\\nResultados - XGBoost\")\nprint(classification_report(y_test, y_pred_xgb))\nprint(\"Mejores parámetros:\", grid_xgb.best_params_)\n\nresultados1.append({\n    \"Modelo\": \"XGBoost\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_xgb),\n    \"Recall\": recall_score(y_test, y_pred_xgb),\n    \"Precision\": precision_score(y_test, y_pred_xgb),\n    \"F1\": f1_score(y_test, y_pred_xgb),\n    \"AUC\": roc_auc_score(y_test, y_pred_xgb),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_xgb.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nConfusionMatrixDisplay.from_estimator(grid_xgb, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - XGBoost\")\n\nRocCurveDisplay.from_estimator(grid_xgb, X_test, y_test, ax=axes[1])\naxes[1].plot([0, 1], [0, 1], \"k--\", label=\"Línea base (y=x)\")\naxes[1].set_title(\"Curva ROC - XGBoost\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo inicial de XGBoost nos da un resultado útil, presentando un rendimiento de prueba sólido con una Accuracy de 0.78 y un AUC de 0.82. La matriz de confusión demuestra un desempeño normal, enfatizando el desbalance que hay entre las clases, ya que la clase mayoritaria (positiva) tiene mayores tasas de clasificacion a diferencia de la clase negativa. En esta ultima clase, la tasa tanto de positivos como negativos es casi equivalente.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.69. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\n","type":"content","url":"/modelos#id-2-1-2-xgboost","position":7},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.3 CatBoost","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"type":"lvl3","url":"/modelos#id-2-1-3-catboost","position":8},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.3 CatBoost","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"content":"\n\ngrid_cat = GridSearchCV(\n    estimator=pipe_cat,\n    param_grid={},\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_cat.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_cat = grid_cat.predict(X_test)\n\nprint(\"\\nResultados - CatBoost\")\nprint(classification_report(y_test, y_pred_cat))\nprint(\"Mejores parámetros:\", grid_cat.best_params_)\n\nresultados1.append({\n    \"Modelo\": \"CatBoost\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_cat),\n    \"Recall\": recall_score(y_test, y_pred_cat),\n    \"Precision\": precision_score(y_test, y_pred_cat),\n    \"F1\": f1_score(y_test, y_pred_cat),\n    \"AUC\": roc_auc_score(y_test, y_pred_cat),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_cat.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nConfusionMatrixDisplay.from_estimator(grid_cat, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - CatBoost\")\n\nRocCurveDisplay.from_estimator(grid_cat, X_test, y_test, ax=axes[1])\naxes[1].plot([0, 1], [0, 1], \"k--\", label=\"Línea base (y=x)\")\naxes[1].set_title(\"Curva ROC - CatBoost\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo inicial de CatBoost nos da un resultado útil, presentando un rendimiento de prueba sólido con una Accuracy de 0.79 y un AUC de 0.84. La matriz de confusión demuestra un desempeño ligeramente moderado, enfatizando el desbalance que hay entre las clases, ya que la clase mayoritaria (positiva) tiene mayores tasas de clasificacion a diferencia de la clase negativa. En esta ultima clase, la tasa tanto de positivos como negativos es casi equivalente.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.71. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\n","type":"content","url":"/modelos#id-2-1-3-catboost","position":9},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.4 LightGBM","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"type":"lvl3","url":"/modelos#id-2-1-4-lightgbm","position":10},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.4 LightGBM","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"content":"\n\ngrid_lgb = GridSearchCV(\n    estimator=pipe_lgb,\n    param_grid={},\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_lgb.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_lgb = grid_lgb.predict(X_test)\n\nprint(\"\\nResultados - LightGBM\")\nprint(classification_report(y_test, y_pred_lgb))\nprint(\"Mejores parámetros:\", grid_lgb.best_params_)\n\nConfusionMatrixDisplay.from_estimator(grid_lgb, X_test, y_test, cmap=\"Blues\")\n\nresultados1.append({\n    \"Modelo\": \"LightGBM\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_lgb),\n    \"Recall\": recall_score(y_test, y_pred_lgb),\n    \"Precision\": precision_score(y_test, y_pred_lgb),\n    \"F1\": f1_score(y_test, y_pred_lgb),\n    \"AUC\": roc_auc_score(y_test, y_pred_lgb),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_lgb.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nConfusionMatrixDisplay.from_estimator(grid_lgb, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - LightGBM\")\n\nRocCurveDisplay.from_estimator(grid_lgb, X_test, y_test, ax=axes[1])\naxes[1].plot([0, 1], [0, 1], \"k--\", label=\"Línea base (y=x)\")\naxes[1].set_title(\"Curva ROC - LightGBM\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\nEl conjunto de resultados del Modelo inicial de LightGBM nos da un resultado útil, presentando un rendimiento de prueba sólido con una Accuracy de 0.79 y un AUC de 0.84. La matriz de confusión demuestra un desempeño normal, enfatizando el desbalance que hay entre las clases, ya que la clase mayoritaria (positiva) tiene mayores tasas de clasificacion a diferencia de la clase negativa. En esta ultima clase, la tasa tanto de positivos como negativos es casi equivalente.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.71. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\n","type":"content","url":"/modelos#id-2-1-4-lightgbm","position":11},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.5 Resultados Preliminares","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"type":"lvl3","url":"/modelos#id-2-1-5-resultados-preliminares","position":12},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.1.5 Resultados Preliminares","lvl2":"2.1 Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM)"},"content":"\n\nres1_df = pd.DataFrame(resultados1)\nres1_df_sorted = res1_df.sort_values(by=\"Recall\", ascending=False)\nprint(\"\\n Resultados finales:\")\ndisplay(res1_df_sorted)\n\nmetricas = [\"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"AUC\"]\n\nres1_df_sorted = res1_df.sort_values(by=\"Recall\", ascending=False).reset_index(drop=True)\n\nres1_melt = res1_df_sorted.melt(\n    id_vars=\"Modelo\", \n    value_vars=metricas, \n    var_name=\"Métrica\", \n    value_name=\"Valor\"\n)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\nsns.barplot(\n    data=res1_melt, \n    x=\"Modelo\", \n    y=\"Valor\", \n    hue=\"Métrica\", \n    palette=\"Blues_r\", \n    ax=axes[0]\n)\naxes[0].set_title(\"Comparación de Métricas por Modelo\", fontsize=14)\naxes[0].set_ylim(0, 1)\naxes[0].set_ylabel(\"Valor de la Métrica\")\naxes[0].set_xlabel(\"Modelo\")\naxes[0].legend(title=\"Métrica\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n\nsns.barplot(\n    data=res1_df_sorted, \n    x=\"Modelo\", \n    y=\"Tiempo (s)\", \n    palette=\"Blues_r\", \n    ax=axes[1]\n)\naxes[1].set_title(\"Tiempo de Entrenamiento por Modelo\", fontsize=14)\naxes[1].set_ylabel(\"Tiempo (segundos)\")\naxes[1].set_xlabel(\"Modelo\")\n\nplt.tight_layout()\nplt.show()\n\n\nDe forma preliminar, vemos que los modelos de CatBoost y LightGBM tienen mejores metricas al comparar con otros modelos. En este caso, la metrica de interes es Recall (ya que queremos reducir los falsos negativos para este caso), y tanto CatBoost como LightGBM alcanzaron los mejores rendimientos. Junto a esto, notamos que CatBoost tuvo una duracion elevada a comparacion del resto (LightGBM, XGBoost y RandomForest)\n\nplt.figure(figsize=(8, 6))\n\nmodelos_entrenados = {\n    \"RandomForest\": grid_rf,\n    \"XGBoost\": grid_xgb,\n    \"CatBoost\": grid_cat,\n    \"LightGBM\": grid_lgb\n}\n\nfor name, model in modelos_entrenados.items():\n    RocCurveDisplay.from_estimator(model, X_test, y_test, ax=plt.gca(), name=name)\n\nplt.plot([0, 1], [0, 1], \"k--\", label=\"Aleatorio\")\n\nplt.title(\"Comparación de Curvas ROC\", fontsize=14)\nplt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\nplt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\nplt.legend(loc=\"lower right\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nComparando curvas ROC, los rendimientos son bastantes similares a la grafica anterior, con LightGBM y CatBoost con un AUC de 0.84, con los modelos restantes estando con 0.82 (XGboost) y 0.81 (RandomForest) respectivamente, teniendo un desempeño similar.\n\n","type":"content","url":"/modelos#id-2-1-5-resultados-preliminares","position":13},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"type":"lvl2","url":"/modelos#id-2-2-modelos-benchmark-randomforest-xgboost-catboost-lightgbm-con-hiperparametros-establecidos","position":14},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"content":"\n\nEn esta seccion, haremos analogamente a lo que hicimos a la seccion anterior, pero implementaremos diferentes hiperparametros para revisar su rendimiento.\n\ndf = pd.read_csv(\"data_churn_EDA.csv\")\n\nX = df.drop(\"churn\", axis=1)\ny = df[\"churn\"]\n\nnum_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\ncat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\npreprocessor = ColumnTransformer([\n    (\"num\", StandardScaler(), num_cols),\n    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n])\n\nprint(\"Categóricas:\", cat_cols)\nprint(\"Numéricas:\", num_cols)\n\nmodels = {\n    \"RandomForest\": RandomForestClassifier(random_state=42),\n    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n    \"CatBoost\": CatBoostClassifier(verbose=0, random_seed=42),\n    \"LightGBM\": LGBMClassifier(random_state=42)\n}\n\npipe_rf = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", RandomForestClassifier(random_state=42))\n])\n\npipe_xgb = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42))\n])\n\npipe_cat = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", CatBoostClassifier(verbose=0, random_seed=42))\n])\n\npipe_lgb = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", LGBMClassifier(random_state=42))\n])\n\n\npipelines = {\n    \"RandomForest\": pipe_rf,\n    \"XGBoost\": pipe_xgb,\n    \"CatBoost\": pipe_cat,\n    \"LightGBM\": pipe_lgb\n}\n\nprint(\" Pipelines creados manualmente para cada modelo:\")\nfor name in pipelines:\n    print(f\" - {name}\")\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nparam_grids = {\n    \"RandomForest\": {\n        \"clf__min_samples_split\": [2, 5, 10],\n        \"clf__min_samples_leaf\": [1, 2, 4],\n        \"clf__max_features\": [\"sqrt\", \"log2\"],\n        \"clf__bootstrap\": [True, False],\n        \"clf__criterion\": [\"gini\", \"entropy\"]\n    },\n    \n    \"XGBoost\": {\n        \"clf__subsample\": [0.8, 1.0],\n        \"clf__gamma\": [0, 1],\n        \"clf__min_child_weight\": [1, 5],\n        \"clf__reg_alpha\": [0, 0.1, 0.5],\n        \"clf__reg_lambda\": [1, 2, 5],\n        \"clf__scale_pos_weight\": [1, 2, 5]\n    },\n\n    \"CatBoost\": {\n        \"clf__l2_leaf_reg\": [1, 3, 5],\n        \"clf__border_count\": [32, 64],\n    },\n\n    \"LightGBM\": {\n        \"clf__min_child_samples\": [10, 20, 50],\n        \"clf__min_child_weight\": [1e-3, 1e-2, 1e-1],\n        \"clf__subsample\": [0.8, 1.0],\n        \"clf__colsample_bytree\": [0.8, 1.0],\n        \"clf__reg_alpha\": [0],\n        \"clf__reg_lambda\": [0, 0.5, 1],\n        \"clf__max_bin\": [255]\n    }\n}\n\nresultados2 = []\n\n","type":"content","url":"/modelos#id-2-2-modelos-benchmark-randomforest-xgboost-catboost-lightgbm-con-hiperparametros-establecidos","position":15},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.1 RandomForest","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-2-1-randomforest","position":16},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.1 RandomForest","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"content":"\n\ngrid_rf = GridSearchCV(\n    estimator=pipe_rf,\n    param_grid=param_grids[\"RandomForest\"],\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_rf.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_rf = grid_rf.predict(X_test)\n\nprint(\"\\n Resultados - RandomForest\")\nprint(classification_report(y_test, y_pred_rf))\nprint(\"---------------------------------------------\")\nprint(\"Mejores parámetros:\", grid_rf.best_params_)\n\nresultados2.append({\n    \"Modelo\": \"RandomForest + HP\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n    \"Recall\": recall_score(y_test, y_pred_rf),\n    \"Precision\": precision_score(y_test, y_pred_rf),\n    \"F1\": f1_score(y_test, y_pred_rf),\n    \"AUC\": roc_auc_score(y_test, y_pred_rf),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_rf.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nConfusionMatrixDisplay.from_estimator(grid_rf, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - RandomForest\")\n\nRocCurveDisplay.from_estimator(grid_rf, X_test, y_test, ax=axes[1], name=\"RandomForest\")\naxes[1].plot([0, 1], [0, 1], \"k--\")\naxes[1].set_title(\"Curva ROC - RandomForest\")\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo Hiperparametrizado de Random Forest nos da un resultado interesante, presentando un rendimiento de prueba sólido con una Accuracy de 0.80 y un AUC de 0.83. La matriz de confusión demuestra un desempeño normal, enfatizando el desbalance que hay entre las clases, ya que la clase mayoritaria (positiva) tiene mayores tasas de clasificacion a diferencia de la clase negativa. En esta ultima clase, la tasa tanto de positivos como negativos es casi equivalente.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.70. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\nLos mejores parametros fueron: {‘clf__bootstrap’: True, ‘clf__criterion’: ‘gini’, ‘clf__max_features’: ‘sqrt’, ‘clf__min_samples_leaf’: 2, ‘clf__min_samples_split’: 5}\n\n","type":"content","url":"/modelos#id-2-2-1-randomforest","position":17},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.2 XGBoost","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-2-2-xgboost","position":18},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.2 XGBoost","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"content":"\n\ngrid_xgb = GridSearchCV(\n    estimator=pipe_xgb,\n    param_grid=param_grids[\"XGBoost\"],\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_xgb.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_xgb = grid_xgb.predict(X_test)\n\nprint(\"\\n Resultados - XGBoost\")\nprint(classification_report(y_test, y_pred_xgb))\nprint(\"---------------------------------------------\")\nprint(\"Mejores parámetros:\", grid_xgb.best_params_)\n\n\nresultados2.append({\n    \"Modelo\": \"XGBoost + HP\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_xgb),\n    \"Recall\": recall_score(y_test, y_pred_xgb),\n    \"Precision\": precision_score(y_test, y_pred_xgb),\n    \"F1\": f1_score(y_test, y_pred_xgb),\n    \"AUC\": roc_auc_score(y_test, y_pred_xgb),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_xgb.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nConfusionMatrixDisplay.from_estimator(grid_xgb, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - XGBoost\")\n\nRocCurveDisplay.from_estimator(grid_xgb, X_test, y_test, ax=axes[1], name=\"XGBoost\")\naxes[1].plot([0, 1], [0, 1], \"k--\")\naxes[1].set_title(\"Curva ROC - XGBoost\")\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo Hiperparametrizado de XGBoost nos da un resultado interesante, presentando un rendimiento de prueba sólido con una Accuracy de 0.71 y un AUC de 0.84. La matriz de confusión demuestra un desempeño diferente al planteado, donde se tuvo una mejoria en la clasificacion de la clase 1, a costo de la clase mayoritaria 0.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.75. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\nLos mejores parametros fueron: {‘clf__gamma’: 1, ‘clf__min_child_weight’: 5, ‘clf__reg_alpha’: 0, ‘clf__reg_lambda’: 5, ‘clf__scale_pos_weight’: 5, ‘clf__subsample’: 1.0}\n\n","type":"content","url":"/modelos#id-2-2-2-xgboost","position":19},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.3 CatBoost","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-2-3-catboost","position":20},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.3 CatBoost","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"content":"\n\ngrid_cat = GridSearchCV(\n    estimator=pipe_cat,\n    param_grid=param_grids[\"CatBoost\"],\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_cat.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_cat = grid_cat.predict(X_test)\n\nprint(\"\\nResultados - CatBoost\")\nprint(classification_report(y_test, y_pred_cat))\nprint(\"---------------------------------------------\")\nprint(\"Mejores parámetros:\", grid_cat.best_params_)\n\nresultados2.append({\n    \"Modelo\": \"CatBoost + HP\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_cat),\n    \"Recall\": recall_score(y_test, y_pred_cat),\n    \"Precision\": precision_score(y_test, y_pred_cat),\n    \"F1\": f1_score(y_test, y_pred_cat),\n    \"AUC\": roc_auc_score(y_test, y_pred_cat),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_cat.best_params_\n})\n\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nConfusionMatrixDisplay.from_estimator(grid_cat, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - CatBoost\")\n\nRocCurveDisplay.from_estimator(grid_cat, X_test, y_test, ax=axes[1])\naxes[1].plot([0, 1], [0, 1], \"k--\")\naxes[1].set_title(\"Curva ROC - CatBoost\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo Hiperparametrizado de CatBoost nos da un resultado interesante, presentando un rendimiento de prueba sólido con una Accuracy de 0.79 y un AUC de 0.83. La matriz de confusión demuestra un desempeño diferente al planteado, donde se tuvo una mejoria en la clasificacion de la clase 1, a costo de la clase mayoritaria 0.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.71. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\nEn este caso, los mejores parametros fueron {‘clf__border_count’: 32, ‘clf__l2_leaf_reg’: 1}\n\n","type":"content","url":"/modelos#id-2-2-3-catboost","position":21},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.4 LightGBM","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-2-4-lightgbm","position":22},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.4 LightGBM","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"content":"\n\ngrid_lgb = GridSearchCV(\n    estimator=pipe_lgb,\n    param_grid=param_grids[\"LightGBM\"],\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_lgb.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_lgb = grid_lgb.predict(X_test)\n\nprint(\"\\nResultados - LightGBM\")\nprint(classification_report(y_test, y_pred_lgb))\nprint(\"Mejores parámetros:\", grid_lgb.best_params_)\n\nConfusionMatrixDisplay.from_estimator(grid_lgb, X_test, y_test, cmap=\"Blues\")\n\nresultados2.append({\n    \"Modelo\": \"LightGBM + HP\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_lgb),\n    \"Recall\": recall_score(y_test, y_pred_lgb),\n    \"Precision\": precision_score(y_test, y_pred_lgb),\n    \"F1\": f1_score(y_test, y_pred_lgb),\n    \"AUC\": roc_auc_score(y_test, y_pred_lgb),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_lgb.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nConfusionMatrixDisplay.from_estimator(grid_lgb, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - LightGBM\")\n\nRocCurveDisplay.from_estimator(grid_lgb, X_test, y_test, ax=axes[1])\naxes[1].plot([0, 1], [0, 1], \"k--\")\naxes[1].set_title(\"Curva ROC - LightGBM\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo Hiperparametrizado de LightGBM nos da un resultado interesante, presentando un rendimiento de prueba sólido con una Accuracy de 0.79 y un AUC de 0.84. La matriz de confusión demuestra un desempeño diferente al planteado, donde se tuvo una mejoria en la clasificacion de la clase 1, a costo de la clase mayoritaria 0.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.70. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\nEn este caso, los mejores parametros fueron: {‘clf__colsample_bytree’: 1.0, ‘clf__max_bin’: 255, ‘clf__min_child_samples’: 10, ‘clf__min_child_weight’: 0.001, ‘clf__reg_alpha’: 0, ‘clf__reg_lambda’: 1, ‘clf__subsample’: 0.8}\n\n","type":"content","url":"/modelos#id-2-2-4-lightgbm","position":23},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.5 Resultados Preliminares","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-2-5-resultados-preliminares","position":24},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.2.5 Resultados Preliminares","lvl2":"2.2. Modelos benchmark (RandomForest, XGboost, CatBoost, LightGBM) con hiperparametros establecidos"},"content":"\n\nres2_df = pd.DataFrame(resultados2)\nres2_df_sorted = res2_df.sort_values(by=\"Recall\", ascending=False)\nprint(\"\\n Resultados finales:\")\ndisplay(res2_df_sorted)\n\nmetricas = [\"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"AUC\"]\n\nres2_df_sorted = res2_df.sort_values(by=\"Recall\", ascending=False).reset_index(drop=True)\n\nres2_melt = res2_df_sorted.melt(\n    id_vars=\"Modelo\", \n    value_vars=metricas, \n    var_name=\"Métrica\", \n    value_name=\"Valor\"\n)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\nsns.barplot(\n    data=res2_melt, \n    x=\"Modelo\", \n    y=\"Valor\", \n    hue=\"Métrica\", \n    palette=\"Blues_r\", \n    ax=axes[0]\n)\naxes[0].set_title(\"Comparación de Métricas por Modelo\", fontsize=14)\naxes[0].set_ylim(0, 1)\naxes[0].set_ylabel(\"Valor de la Métrica\")\naxes[0].set_xlabel(\"Modelo\")\naxes[0].legend(title=\"Métrica\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n\nsns.barplot(\n    data=res2_df_sorted, \n    x=\"Modelo\", \n    y=\"Tiempo (s)\", \n    palette=\"Blues_r\", \n    ax=axes[1]\n)\naxes[1].set_title(\"Tiempo de Entrenamiento por Modelo\", fontsize=14)\naxes[1].set_ylabel(\"Tiempo (segundos)\")\naxes[1].set_xlabel(\"Modelo\")\n\nplt.tight_layout()\nplt.show()\n\n\nDe forma preliminar, vemos que los modelos de CatBoost y XGBoost tienen mejores metricas al comparar con otros modelos. En este caso, la metrica de interes es Recall (ya que queremos reducir los falsos negativos para este caso), y tanto XGBoost como LightGBM alcanzaron los mejores rendimientos. Junto a esto, notamos que XGBoost tuvo una duracion elevada a comparacion del resto (CatBoost, LightGBM y RandomForest)\n\nLos modelos de XGBoost y RandomForest fueron los que menos duracion tuvieron a la hora de ejecutar.\n\nplt.figure(figsize=(8, 6))\n\nmodelos_entrenados = {\n    \"RandomForest\": grid_rf,\n    \"XGBoost\": grid_xgb,\n    \"CatBoost\": grid_cat,\n    \"LightGBM\": grid_lgb\n}\n\nfor name, model in modelos_entrenados.items():\n    RocCurveDisplay.from_estimator(model, X_test, y_test, ax=plt.gca(), name=name)\n\nplt.plot([0, 1], [0, 1], \"k--\", label=\"Aleatorio\")\n\nplt.title(\"Comparación de Curvas ROC /w HP\", fontsize=14)\nplt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\nplt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\nplt.legend(loc=\"lower right\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nComparando curvas ROC, los rendimientos son bastantes similares a la grafica anterior, con LightGBM y XGBoost con un AUC de 0.84, con los modelos restantes estando con 0.83 (RandomForest) y 0.83 (CatBoost) respectivamente, teniendo un desempeño muy similar en comparacion.\n\n","type":"content","url":"/modelos#id-2-2-5-resultados-preliminares","position":25},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"type":"lvl2","url":"/modelos#id-2-3-modelos-con-tecnicas-de-balanceo-gpu-randomforest-xgboost-catboost-lightgbm-e-hiperparametros-establecidos","position":26},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"content":"\n\nPara esta ultima seccion, usaremos los modelos anteriores y aplicaremos el uso de GPU para maximizar el tiempo de computo, manteniendo la complejidad de los modelos, con hiperparametros y validacion cruzada entre estos. Junto a lo anterior, aplicaremos un metodo especifico de balanceo a cada modelo para observar su rendimiento.\n\nprint(\"TensorFlow GPU disponible:\", tf.config.list_physical_devices('GPU'))\n\nX_dummy = np.random.rand(1000, 10)\ny_dummy = np.random.randint(0, 2, 1000)\n\nmodel = XGBClassifier(\n    tree_method=\"gpu_hist\",\n    predictor=\"gpu_predictor\",\n    use_label_encoder=False,\n    eval_metric=\"logloss\"\n)\n\nmodel.fit(X_dummy, y_dummy)\nprint(\"XGBoost entrenado en GPU con éxito.\")\n\nmodel = LGBMClassifier(device=\"gpu\")\nprint(\"LightGBM GPU activo:\", model.get_params()[\"device\"])\n\ndf = pd.read_csv(\"data_churn_EDA.csv\")\n\nX = df.drop(\"churn\", axis=1)\ny = df[\"churn\"]\n\nnum_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\ncat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\npreprocessor = ColumnTransformer([\n    (\"num\", StandardScaler(), num_cols),\n    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n])\n\nprint(\"Categóricas:\", cat_cols)\nprint(\"Numéricas:\", num_cols)\n\nsmote = SMOTE(random_state=42)\n\nn_pos = df['churn'].value_counts()[1]\nn_neg = df['churn'].value_counts()[0]\nw1 = n_neg / n_pos  \nw0 = 1\n\nmodels = {\n    \"RandomForest\": RandomForestClassifier(\n        random_state=42\n    ),\n\n    \"XGBoost\": XGBClassifier(\n        tree_method=\"hist\",\n        predictor=\"cpu_predictor\",  # fuerza CPU en predicción\n        use_label_encoder=False,\n        eval_metric=\"logloss\",\n        scale_pos_weight=w1,  \n        random_state=42\n    ),\n\n    \"LightGBM\": LGBMClassifier(\n        device=\"gpu\",\n        is_unbalance=True, \n        random_state=42\n    )\n}\n\nfrom imblearn.pipeline import Pipeline\n\n\npipe_rf = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"smote\", SMOTE(random_state=42)),  \n    (\"clf\", models[\"RandomForest\"])\n])\n\npipe_xgb = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", models[\"XGBoost\"])\n])\n\npipe_lgb = Pipeline([\n    (\"preprocessor\", preprocessor),\n    (\"clf\", models[\"LightGBM\"]) \n])\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nparam_grids = {\n    \"RandomForest\": {\n        \"clf__min_samples_split\": [2, 5, 10],\n        \"clf__min_samples_leaf\": [1, 2, 4],\n        \"clf__max_features\": [\"sqrt\", \"log2\"],\n        \"clf__bootstrap\": [True, False],\n        \"clf__criterion\": [\"gini\", \"entropy\"]\n    },\n    \"XGBoost\": {\n        \"clf__subsample\": [0.8, 1.0],\n        \"clf__gamma\": [0, 1],\n        \"clf__min_child_weight\": [1, 5],\n        \"clf__reg_alpha\": [0, 0.1, 0.5],\n        \"clf__reg_lambda\": [1, 2, 5],\n        \"clf__scale_pos_weight\": [1, 2, 5]\n    },\n\n    \"LightGBM\": {\n        \"clf__min_child_samples\": [10, 20, 50],\n        \"clf__min_child_weight\": [1e-3, 1e-2, 1e-1],\n        \"clf__subsample\": [0.8, 1.0],\n        \"clf__colsample_bytree\": [0.8, 1.0],\n        \"clf__reg_alpha\": [0],\n        \"clf__reg_lambda\": [0, 0.5, 1],\n        \"clf__max_bin\": [255]\n    }\n}\n\nresultados3 = []\n\n","type":"content","url":"/modelos#id-2-3-modelos-con-tecnicas-de-balanceo-gpu-randomforest-xgboost-catboost-lightgbm-e-hiperparametros-establecidos","position":27},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.3.1 RandomForest","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-3-1-randomforest","position":28},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.3.1 RandomForest","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"content":"\n\ngrid_rf = GridSearchCV(\n    estimator=pipe_rf,\n    param_grid=param_grids[\"RandomForest\"],\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_rf.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_rf = grid_rf.predict(X_test)\n\nprint(\"\\n Resultados - RandomForest\")\nprint(classification_report(y_test, y_pred_rf))\nprint(\"---------------------------------------------\")\nprint(\"Mejores parámetros:\", grid_rf.best_params_)\n\nresultados3.append({\n    \"Modelo\": \"RandomForest + HP + SMOTE (GPU)\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n    \"Recall\": recall_score(y_test, y_pred_rf),\n    \"Precision\": precision_score(y_test, y_pred_rf),\n    \"F1\": f1_score(y_test, y_pred_rf),\n    \"AUC\": roc_auc_score(y_test, y_pred_rf),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_rf.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nConfusionMatrixDisplay.from_estimator(grid_rf, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - RandomForest\")\n\nRocCurveDisplay.from_estimator(grid_rf, X_test, y_test, ax=axes[1], name=\"RandomForest\")\naxes[1].plot([0, 1], [0, 1], \"k--\")\naxes[1].set_title(\"Curva ROC - RandomForest\")\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo Hiperparametrizado + Balaceno y GPU de Random Forest nos da un resultado interesante, presentando un rendimiento de prueba sólido con una Accuracy de 0.76 y un AUC de 0.83. La matriz de confusión demuestra un desempeño normal, enfatizando el desbalance que hay entre las clases, ya que la clase mayoritaria (positiva) tiene mayores tasas de clasificacion a diferencia de la clase negativa. En esta ultima clase, la tasa tanto de positivos como negativos es casi equivalente.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.72. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\nLos mejores parametros fueron: {‘clf__bootstrap’: True, ‘clf__criterion’: ‘gini’, ‘clf__max_features’: ‘log2’, ‘clf__min_samples_leaf’: 4, ‘clf__min_samples_split’: 2}\n\n","type":"content","url":"/modelos#id-2-3-1-randomforest","position":29},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.3.2 XGBoost","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-3-2-xgboost","position":30},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.3.2 XGBoost","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"content":"\n\ngrid_xgb = GridSearchCV(\n    estimator=pipe_xgb,\n    param_grid=param_grids[\"XGBoost\"],\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_xgb.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_xgb = grid_xgb.predict(X_test)\n\nprint(\"\\n Resultados - XGBoost\")\nprint(classification_report(y_test, y_pred_xgb))\nprint(\"---------------------------------------------\")\nprint(\"Mejores parámetros:\", grid_xgb.best_params_)\n\nresultados3.append({\n    \"Modelo\": \"XGBoost + HP + scale_pos_weight=w1 (GPU)\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_xgb),\n    \"Recall\": recall_score(y_test, y_pred_xgb),\n    \"Precision\": precision_score(y_test, y_pred_xgb),\n    \"F1\": f1_score(y_test, y_pred_xgb),\n    \"AUC\": roc_auc_score(y_test, y_pred_xgb),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_xgb.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\nConfusionMatrixDisplay.from_estimator(grid_xgb, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - XGBoost\")\n\nRocCurveDisplay.from_estimator(grid_xgb, X_test, y_test, ax=axes[1], name=\"XGBoost\")\naxes[1].plot([0, 1], [0, 1], \"k--\")\naxes[1].set_title(\"Curva ROC - XGBoost\")\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo Hiperparametrizado + Balaceno y GPU de XGBoost nos da un resultado interesante, presentando un rendimiento de prueba sólido con una Accuracy de 0.71 y un AUC de 0.84. La matriz de confusión demuestra un desempeño normal, enfatizando el desbalance que hay entre las clases, ya que la clase mayoritaria (positiva) tiene mayores tasas de clasificacion a diferencia de la clase negativa. En esta ultima clase, la tasa tanto de positivos como negativos es casi equivalente.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.75. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\nLos mejores parametros fueron: {‘clf__gamma’: 1, ‘clf__min_child_weight’: 5, ‘clf__reg_alpha’: 0, ‘clf__reg_lambda’: 5, ‘clf__scale_pos_weight’: 5, ‘clf__subsample’: 1.0}\n\n","type":"content","url":"/modelos#id-2-3-2-xgboost","position":31},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.3.4 LightGBM","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-3-4-lightgbm","position":32},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.3.4 LightGBM","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"content":"\n\ngrid_lgb = GridSearchCV(\n    estimator=pipe_lgb,\n    param_grid=param_grids[\"LightGBM\"],\n    scoring=\"recall\",\n    cv=cv,\n    n_jobs=-1,\n    verbose=1\n)\n\ninicio = time.time()\ngrid_lgb.fit(X_train, y_train)\nfin = time.time()\n\ny_pred_lgb = grid_lgb.predict(X_test)\n\nprint(\"\\nResultados - LightGBM\")\nprint(classification_report(y_test, y_pred_lgb))\nprint(\"Mejores parámetros:\", grid_lgb.best_params_)\n\nConfusionMatrixDisplay.from_estimator(grid_lgb, X_test, y_test, cmap=\"Blues\")\n\nresultados3.append({\n    \"Modelo\": \"LightGBM + HP + is_unbalance=True (GPU)\",\n    \"Accuracy\": accuracy_score(y_test, y_pred_lgb),\n    \"Recall\": recall_score(y_test, y_pred_lgb),\n    \"Precision\": precision_score(y_test, y_pred_lgb),\n    \"F1\": f1_score(y_test, y_pred_lgb),\n    \"AUC\": roc_auc_score(y_test, y_pred_lgb),\n    \"Tiempo (s)\": round(fin - inicio, 2),\n    \"Mejores Parámetros\": grid_lgb.best_params_\n})\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\nConfusionMatrixDisplay.from_estimator(grid_lgb, X_test, y_test, cmap=\"Blues\", ax=axes[0])\naxes[0].set_title(\"Matriz de Confusión - LightGBM\")\n\nRocCurveDisplay.from_estimator(grid_lgb, X_test, y_test, ax=axes[1])\naxes[1].plot([0, 1], [0, 1], \"k--\")\naxes[1].set_title(\"Curva ROC - LightGBM\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nEl conjunto de resultados del Modelo Hiperparametrizado + Balaceno y GPU de XGBoost nos da un resultado interesante, presentando un rendimiento de prueba sólido con una Accuracy de 0.76 y un AUC de 0.84. La matriz de confusión demuestra un desempeño normal, enfatizando el desbalance que hay entre las clases, ya que la clase mayoritaria (positiva) tiene mayores tasas de clasificacion a diferencia de la clase negativa. En esta ultima clase, la tasa tanto de positivos como negativos es casi equivalente.\n\nEl reporte de clasificación muestra que el modelo es mejor en la identificación de la clase ‘0’ (clase 1), logrando un Recall de 0.75. Este rendimiento indica una situacion interesante de desbalanceo entre las clases, y veremos si esto cambia a medida que implementemos diversos metodos de balanceo e hiperparametrizacion.\n\nLos mejores parametros fueron: {‘clf__colsample_bytree’: 1.0, ‘clf__max_bin’: 255, ‘clf__min_child_samples’: 50, ‘clf__min_child_weight’: 0.001, ‘clf__reg_alpha’: 0, ‘clf__reg_lambda’: 0.5, ‘clf__subsample’: 0.8}\n\n","type":"content","url":"/modelos#id-2-3-4-lightgbm","position":33},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.3.5 Resultados preliminares","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"type":"lvl3","url":"/modelos#id-2-3-5-resultados-preliminares","position":34},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl3":"2.3.5 Resultados preliminares","lvl2":"2.3 Modelos con tecnicas de balanceo + GPU (RandomForest, XGboost, CatBoost, LightGBM) e hiperparametros establecidos"},"content":"\n\nres3_df = pd.DataFrame(resultados3)\nres3_df_sorted = res3_df.sort_values(by=\"Recall\", ascending=False)\nprint(\"\\n Resultados finales:\")\ndisplay(res3_df_sorted)\n\nmetricas = [\"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"AUC\"]\n\nres3_df_sorted = res3_df.sort_values(by=\"Recall\", ascending=False).reset_index(drop=True)\n\nres3_melt = res3_df_sorted.melt(\n    id_vars=\"Modelo\", \n    value_vars=metricas, \n    var_name=\"Métrica\", \n    value_name=\"Valor\"\n)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\nsns.barplot(\n    data=res3_melt, \n    x=\"Modelo\", \n    y=\"Valor\", \n    hue=\"Métrica\", \n    palette=\"Blues_r\", \n    ax=axes[0]\n)\naxes[0].set_title(\"Comparación de Métricas por Modelo\", fontsize=14)\naxes[0].set_ylim(0, 1)\naxes[0].set_ylabel(\"Valor de la Métrica\")\naxes[0].set_xlabel(\"Modelo\")\naxes[0].legend(title=\"Métrica\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n\nsns.barplot(\n    data=res3_df_sorted, \n    x=\"Modelo\", \n    y=\"Tiempo (s)\", \n    palette=\"Blues_r\", \n    ax=axes[1]\n)\naxes[1].set_title(\"Tiempo de Entrenamiento por Modelo\", fontsize=14)\naxes[1].set_ylabel(\"Tiempo (segundos)\")\naxes[1].set_xlabel(\"Modelo\")\n\nplt.tight_layout()\nplt.show()\n\n\nDe forma preliminar, vemos que los modelos de XGBoost y LightGBM tienen mejores metricas al comparar con otros modelos. En este caso, la metrica de interes es Recall (ya que queremos reducir los falsos negativos para este caso), y XGBoost alcanzó los mejores rendimientos. Junto a esto, notamos que XGBoost tuvo una duracion elevada a comparacion del resto (LightGBM y RandomForest)\n\nLos modelos de XGBoost y RandomForest fueron los que menos duracion tuvieron a la hora de ejecutar.\n\nplt.figure(figsize=(8, 6))\n\nmodelos_entrenados = {\n    \"RandomForest\": grid_rf,\n    \"XGBoost\": grid_xgb,\n    \"LightGBM\": grid_lgb\n}\n\nfor name, model in modelos_entrenados.items():\n    RocCurveDisplay.from_estimator(model, X_test, y_test, ax=plt.gca(), name=name)\n\nplt.plot([0, 1], [0, 1], \"k--\", label=\"Aleatorio\")\n\nplt.title(\"Comparación de Curvas ROC /w HP\", fontsize=14)\nplt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\nplt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\nplt.legend(loc=\"lower right\")\nplt.grid(alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nComparando curvas ROC, los rendimientos son bastantes similares a la grafica anterior, con LightGBM y XGBoost con un AUC de 0.84, con los modelos restantes estando con 0.83 (RandomForest) respectivamente, teniendo un desempeño muy similar en comparacion.\n\n","type":"content","url":"/modelos#id-2-3-5-resultados-preliminares","position":35},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl2":"2.4 Resultados generales"},"type":"lvl2","url":"/modelos#id-2-4-resultados-generales","position":36},{"hierarchy":{"lvl1":"2. Preprocesamiento de datos y Modelados","lvl2":"2.4 Resultados generales"},"content":"\n\nres_all = pd.concat([res1_df, res2_df, res3_df], ignore_index=True)\n\nres_all_sorted = res_all.sort_values(by=\"Recall\", ascending=False)\n\nprint(\"\\nResultados combinados:\")\ndisplay(res_all_sorted)\n\nmetricas = [\"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"AUC\"]\n\nres_all_melt = res_all.melt(\n    id_vars=[\"Modelo\"], \n    value_vars=metricas,\n    var_name=\"Métrica\",\n    value_name=\"Valor\"\n)\n\n\ntop5 = res_all_sorted.nlargest(5, \"Recall\")\n\ntop5_melt = top5.melt(\n    id_vars=[\"Modelo\"],\n    value_vars=[\"Accuracy\", \"Recall\", \"Precision\", \"F1\", \"AUC\"],\n    var_name=\"Métrica\",\n    value_name=\"Valor\"\n)\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\nsns.barplot(\n    data=top5_melt, \n    x=\"Modelo\", \n    y=\"Valor\", \n    hue=\"Métrica\", \n    palette=\"Blues_r\", \n    ax=axes[0]\n)\n\naxes[0].set_title(\"Top 5 Modelos - Comparación de Métricas\", fontsize=14)\naxes[0].set_ylim(0, 1)\naxes[0].set_ylabel(\"Valor de la Métrica\")\naxes[0].set_xlabel(\"Modelo\")\naxes[0].grid(alpha=0.3)\n\naxes[0].set_xticklabels(\n    axes[0].get_xticklabels(),\n    rotation=35,\n    ha=\"right\",\n    fontsize=11\n)\n\nfor p in axes[0].patches:\n    value = p.get_height()\n    if not np.isnan(value) and value > 0.01:  \n        axes[0].text(\n            p.get_x() + p.get_width() / 2,\n            value + 0.015,\n            f\"{value:.2f}\",\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=9,\n            color=\"black\"\n        )\n\naxes[0].legend(title=\"Métrica\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n\nsns.barplot(\n    data=top5, \n    x=\"Modelo\", \n    y=\"Tiempo (s)\", \n    palette=\"Blues_r\", \n    ax=axes[1]\n)\n\naxes[1].set_title(\"Top 5 Modelos - Tiempo de Entrenamiento\", fontsize=14)\naxes[1].set_ylabel(\"Tiempo (segundos)\")\naxes[1].set_xlabel(\"Modelo\")\naxes[1].grid(alpha=0.3)\n\naxes[1].set_xticklabels(\n    axes[1].get_xticklabels(),\n    rotation=35,\n    ha=\"right\",\n    fontsize=11\n)\n\nfor p in axes[1].patches:\n    value = p.get_height()\n    if not np.isnan(value):\n        axes[1].text(\n            p.get_x() + p.get_width() / 2,\n            value + (value * 0.02),\n            f\"{value:.2f}s\",\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=9,\n            color=\"black\"\n        )\n\nplt.tight_layout()\nplt.show()\n\n\nTras todos los modeladados, tenemos estos resultados en base a las metricas que hemos planteado. En base a esto, vemos que los mejores modelos fueron una combinacion entre hiperparametrizar, usar balaceno y GPU. Para esto, observaremos los mejores tres modelos:\n\nEl mejor modelo a estudio fue XGBoost + Hiperparametros, que alcanzo 0.848 en recall.Y tuvo el menor tiempo de computo a comparacion del resto de los modelos.\n\nEl segundo mejor modelo fue una combinacion de XGBoost + Hiperparametros y tecnicas de balanceo, que a pesar de tener un tiempo de computo elevado, tuvo una metrica de recall global de 0.840.\n\nEn tercer lugar fue el modelo de LightGBM con las mismas especificaciones que el segundo modelo, que tuvo un desempeño moderado, con un recall global de 0.743.\n\nplt.figure(figsize=(10, 6))\n\nres_sorted = res_all_sorted.sort_values(\"Recall\", ascending=False)\n\nsns.barplot(\n    data=res_sorted,\n    x=\"Modelo\",\n    y=\"Recall\",\n    palette=\"Blues_r\"\n)\n\nplt.title(\"Comparación Global de Recall por Modelo\", fontsize=14)\nplt.ylabel(\"Recall\")\nplt.xlabel(\"Modelo\")\nplt.ylim(0, 1)\nplt.xticks(rotation=45, ha=\"right\")\nplt.grid(alpha=0.3)\n\nfor i, val in enumerate(res_sorted[\"Recall\"]):\n    plt.text(\n        i,\n        val + 0.015,  \n        f\"{val:.3f}\",\n        ha=\"center\",\n        va=\"bottom\",\n        fontsize=10,\n        color=\"black\"\n    )\n\nmean_recall = res_sorted[\"Recall\"].mean()\nplt.axhline(mean_recall, color=\"black\", linestyle=\"--\", linewidth=1)\nplt.text(\n    len(res_sorted) - 0.5, mean_recall + 0.015,\n    f\"Promedio: {mean_recall:.3f}\",\n    color=\"black\",\n    fontsize=10,\n    ha=\"right\",\n    va=\"bottom\",\n    fontweight=\"bold\"\n)\n\nbest_model = res_sorted.iloc[0]\noffset = 0.08 \nplt.text(\n    x=0,\n    y=min(best_model[\"Recall\"] + offset, 0.98), \n    s=f\"Mejor modelo: {best_model['Modelo']} ({best_model['Recall']:.3f})\",\n    fontsize=12,\n    color=sns.color_palette(\"Blues\")[-1],\n    fontweight=\"bold\"\n)\n\nplt.tight_layout()\nplt.show()\n\n\nObservandolo de otra perspectiva, esta es una comparacion solamente de recall por modelos, observando los valores que hay entre los diferentes modelos, de forma ascendente, con el promedio de los modelos tambien especificado. Aqui, XGBoost + HP fue coronado como el mejor modelo en terminos de tanto metricas globales, como en la metrica objetivo, la cual fue Recall.","type":"content","url":"/modelos#id-2-4-resultados-generales","position":37},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance"},"type":"lvl1","url":"/interpretables-resultados","position":0},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance"},"content":"Ahora, usaremos los mejores modelos de cada seccion, y observamos el feature importance de cada uno, ejemplificandolo con diversos casos dentro de los datos estudiados.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom lime.lime_tabular import LimeTabularExplainer\nimport pickle\n\nimport joblib\n\n","type":"content","url":"/interpretables-resultados","position":1},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.1 XGBoost Hiperparametrizado"},"type":"lvl2","url":"/interpretables-resultados#id-3-1-xgboost-hiperparametrizado","position":2},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.1 XGBoost Hiperparametrizado"},"content":"\n\nActo siguiente, vamos a observar cuales fueron las diez features mas importantes por modelo, de forma descendente.\n\nxgb_final = joblib.load(\"xgb_hp_best.pkl\")\n\nxgb_final\n\n\nxgb_model = list(xgb_final.named_steps.values())[-1] \nfeature_names = xgb_final.named_steps[\"preprocessor\"].get_feature_names_out()\nimportances = xgb_model.feature_importances_\n\nfeat_importance = (\n    pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n    .sort_values(by=\"Importance\", ascending=False)\n    .reset_index(drop=True)\n)\n\ntop10 = feat_importance.head(10)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(data=top10, x=\"Importance\", y=\"Feature\", palette=\"Blues_r\")\nplt.title(\"Top 10 Features más importantes — XGBoost + HP\", fontsize=14)\nplt.xlabel(\"Importancia\")\nplt.ylabel(\"Características\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\nAqui, los features mas importantes fueron:\n\ncat_contract_Month-to-month, cat_internet_Fiber optic, cat_streaming_movies_Yes, cat_contract_One year, cat_internet_security_no\n\n","type":"content","url":"/interpretables-resultados#id-3-1-xgboost-hiperparametrizado","position":3},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.1.1 Caso mixto de Churn (i=10)","lvl2":"3.1 XGBoost Hiperparametrizado"},"type":"lvl3","url":"/interpretables-resultados#id-3-1-1-caso-mixto-de-churn-i-10","position":4},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.1.1 Caso mixto de Churn (i=10)","lvl2":"3.1 XGBoost Hiperparametrizado"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #10 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = xgb_final.named_steps[\"preprocessor\"]\nclassifier = xgb_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 10\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 10  \nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME — XGBoost + HP (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n🎨 Significado de los colores rojo y azul\n\nEn la gráfica que generamos:\n\n🔴 Rojo → La característica empuja la predicción hacia la clase positiva (por ejemplo, “Sí churn”).\n\n🔵 Azul → La característica empuja la predicción hacia la clase negativa (por ejemplo, “No churn”).\n\n⚙️ Interpretación práctica (en tu contexto de churn)\n\nSupongamos que el modelo predice si un cliente hará churn (“Sí”) o no (“No”).\nEntonces:\n\nColor\tSignificado\tEjemplo\n🔴 Rojo\tContribuye a que el modelo prediga “Sí churn”\ttenure bajo o MonthlyCharges alto hacen más probable que se vaya\n🔵 Azul\tContribuye a que el modelo prediga “No churn”\ttenure alto o contract tipo “two year” hacen menos probable que se vaya\n\n","type":"content","url":"/interpretables-resultados#id-3-1-1-caso-mixto-de-churn-i-10","position":5},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.1.2 Caso positivo de Churn (i=100)","lvl2":"3.1 XGBoost Hiperparametrizado"},"type":"lvl3","url":"/interpretables-resultados#id-3-1-2-caso-positivo-de-churn-i-100","position":6},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.1.2 Caso positivo de Churn (i=100)","lvl2":"3.1 XGBoost Hiperparametrizado"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #100 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = xgb_final.named_steps[\"preprocessor\"]\nclassifier = xgb_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 100\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 100\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME — XGBoost + HP (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-1-2-caso-positivo-de-churn-i-100","position":7},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.1.3 Caso negativo de Churn (i=500)","lvl2":"3.1 XGBoost Hiperparametrizado"},"type":"lvl3","url":"/interpretables-resultados#id-3-1-3-caso-negativo-de-churn-i-500","position":8},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.1.3 Caso negativo de Churn (i=500)","lvl2":"3.1 XGBoost Hiperparametrizado"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #500 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = xgb_final.named_steps[\"preprocessor\"]\nclassifier = xgb_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 500\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 500\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME — XGBoost + HP (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-1-3-caso-negativo-de-churn-i-500","position":9},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.2 LightGBM usando Hiperparametrizacion e is_unbalance=True (GPU)"},"type":"lvl2","url":"/interpretables-resultados#id-3-2-lightgbm-usando-hiperparametrizacion-e-is-unbalance-true-gpu","position":10},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.2 LightGBM usando Hiperparametrizacion e is_unbalance=True (GPU)"},"content":"\n\nActo siguiente, vamos a observar cuales fueron las diez features mas importantes por modelo, de forma descendente.\n\nlgb_final = joblib.load(\"lgb_hp_best.pkl\")\n\nlgb_final\n\n\nlgb_model = list(lgb_final.named_steps.values())[-1] \nfeature_names = lgb_final.named_steps[\"preprocessor\"].get_feature_names_out()\nimportances = lgb_model.feature_importances_\n\nfeat_importance = (\n    pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n    .sort_values(by=\"Importance\", ascending=False)\n    .reset_index(drop=True)\n)\n\n\ntop10 = feat_importance.head(10)\n\n\nplt.figure(figsize=(10, 6))\nsns.barplot(data=top10, x=\"Importance\", y=\"Feature\", palette=\"Blues_r\")\nplt.title(\"Top 10 Features más importantes — LightGBM + HP + is_unbalance=True\", fontsize=14)\nplt.xlabel(\"Importancia\")\nplt.ylabel(\"Características\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n\nAqui, los features mas importantes fueron:\n\nnum_charges_monthly, num_tenure, cat_payment_Electronic check, cat_dependents_no, cat_internet_security_no\n\n","type":"content","url":"/interpretables-resultados#id-3-2-lightgbm-usando-hiperparametrizacion-e-is-unbalance-true-gpu","position":11},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.2.1 Caso mixto de Churn (i=10)","lvl2":"3.2 LightGBM usando Hiperparametrizacion e is_unbalance=True (GPU)"},"type":"lvl3","url":"/interpretables-resultados#id-3-2-1-caso-mixto-de-churn-i-10","position":12},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.2.1 Caso mixto de Churn (i=10)","lvl2":"3.2 LightGBM usando Hiperparametrizacion e is_unbalance=True (GPU)"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #10 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = lgb_final.named_steps[\"preprocessor\"]\nclassifier = lgb_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 10\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 10  \nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME — LightGBM + HP + is_unbalance=True (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-2-1-caso-mixto-de-churn-i-10","position":13},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.2.2 Caso positivo de Churn (i=100)","lvl2":"3.2 LightGBM usando Hiperparametrizacion e is_unbalance=True (GPU)"},"type":"lvl3","url":"/interpretables-resultados#id-3-2-2-caso-positivo-de-churn-i-100","position":14},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.2.2 Caso positivo de Churn (i=100)","lvl2":"3.2 LightGBM usando Hiperparametrizacion e is_unbalance=True (GPU)"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #100 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = lgb_final.named_steps[\"preprocessor\"]\nclassifier = lgb_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 100\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 100\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME — LightGBM + HP + is_unbalance=True (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-2-2-caso-positivo-de-churn-i-100","position":15},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.2.3 Caso negativo de Churn (i=500)","lvl2":"3.2 LightGBM usando Hiperparametrizacion e is_unbalance=True (GPU)"},"type":"lvl3","url":"/interpretables-resultados#id-3-2-3-caso-negativo-de-churn-i-500","position":16},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.2.3 Caso negativo de Churn (i=500)","lvl2":"3.2 LightGBM usando Hiperparametrizacion e is_unbalance=True (GPU)"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #500 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = lgb_final.named_steps[\"preprocessor\"]\nclassifier = lgb_final.named_steps[\"clf\"]\n\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 500\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 500\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME — LightGBM + HP + is_unbalance=True (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-2-3-caso-negativo-de-churn-i-500","position":17},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.3 RandomForest usando Hiperparametrizacion y SMOTE (GPU)"},"type":"lvl2","url":"/interpretables-resultados#id-3-3-randomforest-usando-hiperparametrizacion-y-smote-gpu","position":18},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.3 RandomForest usando Hiperparametrizacion y SMOTE (GPU)"},"content":"\n\nActo siguiente, vamos a observar cuales fueron las diez features mas importantes por modelo, de forma descendente.\n\nrf_final = joblib.load(\"rf_smote_best.pkl\")\n\nrf_final\n\n\nrf_model = list(rf_final.named_steps.values())[-1] \nfeature_names = rf_final.named_steps[\"preprocessor\"].get_feature_names_out()\nimportances = rf_model.feature_importances_\n\nfeat_importance = (\n    pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n    .sort_values(by=\"Importance\", ascending=False)\n    .reset_index(drop=True)\n)\n\ntop10 = feat_importance.head(10)\n\n\nplt.figure(figsize=(10, 6))\nsns.barplot(data=top10, x=\"Importance\", y=\"Feature\", palette=\"Blues_r\")\nplt.title(\"Top 10 Features más importantes — RandomForest + HP + SMOTE\", fontsize=14)\nplt.xlabel(\"Importancia\")\nplt.ylabel(\"Características\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n\nAqui, los features mas importantes fueron:\n\nnum_tenure, cat_contract_Month-to-month, cat_internet_security_no, cat_contract_Two year, y cat_payment_Electronic check\n\n","type":"content","url":"/interpretables-resultados#id-3-3-randomforest-usando-hiperparametrizacion-y-smote-gpu","position":19},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.1 Caso mixto de Churn (i=10)","lvl2":"3.3 RandomForest usando Hiperparametrizacion y SMOTE (GPU)"},"type":"lvl3","url":"/interpretables-resultados#id-3-3-1-caso-mixto-de-churn-i-10","position":20},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.1 Caso mixto de Churn (i=10)","lvl2":"3.3 RandomForest usando Hiperparametrizacion y SMOTE (GPU)"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #10 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = rf_final.named_steps[\"preprocessor\"]\nclassifier = rf_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 10\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 10  \nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME —  RandomForest + HP + SMOTE (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-3-1-caso-mixto-de-churn-i-10","position":21},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.2 Caso positivo de Churn (i=100)","lvl2":"3.3 RandomForest usando Hiperparametrizacion y SMOTE (GPU)"},"type":"lvl3","url":"/interpretables-resultados#id-3-3-2-caso-positivo-de-churn-i-100","position":22},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.2 Caso positivo de Churn (i=100)","lvl2":"3.3 RandomForest usando Hiperparametrizacion y SMOTE (GPU)"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #100 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = rf_final.named_steps[\"preprocessor\"]\nclassifier = rf_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 100\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 100\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME —  RandomForest + HP + SMOTE (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-3-2-caso-positivo-de-churn-i-100","position":23},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.3 Caso negativo de Churn (i=500)","lvl2":"3.3 RandomForest usando Hiperparametrizacion y SMOTE (GPU)"},"type":"lvl3","url":"/interpretables-resultados#id-3-3-3-caso-negativo-de-churn-i-500","position":24},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.3 Caso negativo de Churn (i=500)","lvl2":"3.3 RandomForest usando Hiperparametrizacion y SMOTE (GPU)"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #500 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = rf_final.named_steps[\"preprocessor\"]\nclassifier = rf_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 500\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 500\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME — RandomForest + HP + SMOTE (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-3-3-caso-negativo-de-churn-i-500","position":25},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.4 CatBoost Hiperparametrizado"},"type":"lvl2","url":"/interpretables-resultados#id-3-4-catboost-hiperparametrizado","position":26},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.4 CatBoost Hiperparametrizado"},"content":"\n\nAqui, vamos a primero cargar el modelo.\n\ncat_final = joblib.load(\"cat_hp_best.pkl\")\n\ncat_final\n\nActo siguiente, vamos a observar cuales fueron las diez features mas importantes por modelo, de forma descendente.\n\ncat_model = list(cat_final.named_steps.values())[-1] \nfeature_names = cat_final.named_steps[\"preprocessor\"].get_feature_names_out()\nimportances = cat_model.feature_importances_\n\nfeat_importance = (\n    pd.DataFrame({\"Feature\": feature_names, \"Importance\": importances})\n    .sort_values(by=\"Importance\", ascending=False)\n    .reset_index(drop=True)\n)\n\n\ntop10 = feat_importance.head(10)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(data=top10, x=\"Importance\", y=\"Feature\", palette=\"Blues_r\")\nplt.title(\"Top 10 Features más importantes — CatBoost + HP\", fontsize=14)\nplt.xlabel(\"Importancia\")\nplt.ylabel(\"Características\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n\nAqui, los features mas importantes fueron:\n\nnum_tenure, num_charges_monthly, cat_contract_Month-to-month, cat_payment_Electronic check y cat_payment_Back transfor (automatic)\n\n","type":"content","url":"/interpretables-resultados#id-3-4-catboost-hiperparametrizado","position":27},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.1 Caso mixto de Churn (i=10)","lvl2":"3.4 CatBoost Hiperparametrizado"},"type":"lvl3","url":"/interpretables-resultados#id-3-3-1-caso-mixto-de-churn-i-10-1","position":28},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.1 Caso mixto de Churn (i=10)","lvl2":"3.4 CatBoost Hiperparametrizado"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #10 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = cat_final.named_steps[\"preprocessor\"]\nclassifier = cat_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 10\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 10  \nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME —  CatBoost + HP (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-3-1-caso-mixto-de-churn-i-10-1","position":29},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.2 Caso positivo de Churn (i=100)","lvl2":"3.4 CatBoost Hiperparametrizado"},"type":"lvl3","url":"/interpretables-resultados#id-3-3-2-caso-positivo-de-churn-i-100-1","position":30},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.2 Caso positivo de Churn (i=100)","lvl2":"3.4 CatBoost Hiperparametrizado"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #100 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = cat_final.named_steps[\"preprocessor\"]\nclassifier = cat_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 100\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 100\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME —  CatBoost + HP  (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-3-2-caso-positivo-de-churn-i-100-1","position":31},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.3 Caso negativo de Churn (i=500)","lvl2":"3.4 CatBoost Hiperparametrizado"},"type":"lvl3","url":"/interpretables-resultados#id-3-3-3-caso-negativo-de-churn-i-500-1","position":32},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl3":"3.3.3 Caso negativo de Churn (i=500)","lvl2":"3.4 CatBoost Hiperparametrizado"},"content":"\n\nPara esta seccion, vamos a ver como se compara este modelo con el registro #500 del dataset estudiado, y ver como se comparan los modelos y sus feature importances.\n\npreprocessor = cat_final.named_steps[\"preprocessor\"]\nclassifier = cat_final.named_steps[\"clf\"]\n\nX_train_trans = preprocessor.transform(X_train)\nX_test_trans = preprocessor.transform(X_test)\nfeature_names = preprocessor.get_feature_names_out()\n\nexplainer = LimeTabularExplainer(\n    training_data=np.array(X_train_trans),\n    feature_names=feature_names,\n    class_names=[\"No Churn\", \"Sí Churn\"],\n    mode=\"classification\"\n)\n\ni = 500\n\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=classifier.predict_proba,\n    num_features=10\n)\n\npred_proba = classifier.predict_proba([X_test_trans[i]])[0]\npred_class = np.argmax(pred_proba)\n\nlime_features = exp.as_list()\ndf_lime = pd.DataFrame(lime_features, columns=[\"Característica\", \"Peso\"])\ndf_lime[\"abs_peso\"] = df_lime[\"Peso\"].abs()\ndf_lime = df_lime.sort_values(by=\"abs_peso\", ascending=False).reset_index(drop=True)\n\nprint(\"=\" * 80)\nprint(f\"Interpretación LIME — Caso #{i}\")\nprint(\"-\" * 80)\nprint(f\"Clase predicha: {'Sí Churn ' if pred_class == 1 else 'No Churn '}\")\nprint(f\"Probabilidades -> No: {pred_proba[0]:.3f} | Sí: {pred_proba[1]:.3f}\")\nprint(\"\\nTop 10 características más influyentes:\")\nprint(df_lime[[\"Característica\", \"Peso\"]].to_string(index=False))\nprint(\"=\" * 80)\n\n\ni = 500\nexp = explainer.explain_instance(\n    data_row=X_test_trans[i],\n    predict_fn=xgb_model.predict_proba,\n    num_features=10\n)\n\nexp.show_in_notebook(show_table=True)\n\nplt.figure(figsize=(8, 6))\ncolors = [\"#d62728\" if w > 0 else \"#1f77b4\" for w in df_lime[\"Peso\"]]\n\nsns.barplot(\n    data=df_lime.sort_values(by=\"Peso\", ascending=True),\n    x=\"Peso\",\n    y=\"Característica\",\n    palette=colors\n)\n\nplt.title(f\"LIME — CatBoost + HP (Caso #{i})\", fontsize=13)\nplt.xlabel(\"Impacto en la predicción (Peso)\")\nplt.ylabel(\"\")\nplt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/interpretables-resultados#id-3-3-3-caso-negativo-de-churn-i-500-1","position":33},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.5 Comparacion final entre modelos"},"type":"lvl2","url":"/interpretables-resultados#id-3-5-comparacion-final-entre-modelos","position":34},{"hierarchy":{"lvl1":"3. Interpretabilidad y feature_importance","lvl2":"3.5 Comparacion final entre modelos"},"content":"\n\nmodels = {\n    \"XGBoost + HP\": pipe_xgb,\n    \"LightGBM + HP + is_unbalanced=True (GPU)\": pipe_lgb,\n    \"RandomForest + HP + SMOTE (GPU)\": pipe_rf,\n    \"CatBoost + HP\": pipe_cat\n}\n\nfeature_orig = X_train.columns\n\n\nmodels_fitted = {\n    \"XGBoost + HP\": grid_xgb.best_estimator_,\n    \"LightGBM + HP + is_unbalanced=True (GPU)\": grid_lgb.best_estimator_,\n    \"RandomForest + HP + SMOTE (GPU)\": grid_rf.best_estimator_,\n    \"CatBoost + HP\": grid_cat.best_estimator_\n}\n\n\nfeature_importances = {}\n\nfor name, pipe in models_fitted.items():\n    feature_names = pipe.named_steps[\"preprocessor\"].get_feature_names_out()\n    clf = pipe.named_steps[\"clf\"]\n\n    if hasattr(clf, \"feature_importances_\"):\n        importances = clf.feature_importances_\n    elif \"CatBoost\" in name:\n        importances = clf.get_feature_importance()\n    else:\n        importances = np.zeros(len(feature_names))\n\n    df_imp = pd.DataFrame({\n        \"Feature\": feature_names,\n        \"Importance\": importances\n    }).sort_values(\"Importance\", ascending=False).reset_index(drop=True)\n\n    feature_importances[name] = df_imp\n\n\n\nplt.figure(figsize=(18, 12))\nfor i, (name, df_imp) in enumerate(feature_importances.items(), 1):\n    plt.subplot(2, 2, i)\n    top10 = df_imp.head(10)\n    sns.barplot(\n        data=top10.sort_values(\"Importance\", ascending=True),\n        x=\"Importance\",\n        y=\"Feature\",\n        palette=\"Blues\"\n    )\n    plt.title(f\"Top 10 Features — {name}\", fontsize=12)\n    plt.xlabel(\"Importancia\")\n    plt.ylabel(\"\")\n    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n\nplt.tight_layout()\nplt.show()\n\n\ntop_n = 21  \nall_features = set()\n\nfor df in feature_importances.values():\n    all_features.update(df.head(top_n)[\"Feature\"].tolist())\n\nall_features = list(all_features)\n\nheatmap_df = pd.DataFrame(index=all_features)\n\nfor name, df in feature_importances.items():\n    temp = df.set_index(\"Feature\")[\"Importance\"]\n    heatmap_df[name] = temp\n\nheatmap_df = heatmap_df.fillna(0)\n\nheatmap_norm = heatmap_df / heatmap_df.max()\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(\n    heatmap_norm, \n    annot=True, \n    cmap=\"Blues\", \n    cbar_kws={'label': 'Importancia relativa'}, \n    linewidths=0.5\n)\nplt.title(\"Comparación de Feature Importances - Top Features\", fontsize=16)\nplt.ylabel(\"Características\")\nplt.xlabel(\"Modelo\")\nplt.tight_layout()\nplt.show()\n","type":"content","url":"/interpretables-resultados#id-3-5-comparacion-final-entre-modelos","position":35}]}